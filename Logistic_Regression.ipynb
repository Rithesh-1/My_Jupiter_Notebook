{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOS3mCd51cbNpzxZWFstLzL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"bFo6A3dwL7s1"},"outputs":[],"source":["# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load in\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import matplotlib.pyplot as plt # data visualization\n","import seaborn as sns # statistical data visualization\n","%matplotlib inline\n","\n","# Input data files are available in the \"../input/\" directory.\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# Any results you write to the current directory are saved as output."]},{"cell_type":"code","source":["import warnings\n","\n","warnings.filterwarnings('ignore')"],"metadata":{"id":"X7DT4jDCmFqE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = '/kaggle/input/weather-dataset-rattle-package/weatherAUS.csv'\n","\n","df = pd.read_csv(data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":373},"id":"3TLY4fKImKJO","executionInfo":{"status":"error","timestamp":1718282144741,"user_tz":-330,"elapsed":1093,"user":{"displayName":"The Ghost Man","userId":"00574377802751596480"}},"outputId":"dd4315e8-e079-4117-a9d3-2babac214a76"},"execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/kaggle/input/weather-dataset-rattle-package/weatherAUS.csv'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-167d6465f4dd>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/kaggle/input/weather-dataset-rattle-package/weatherAUS.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1661\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1662\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/weather-dataset-rattle-package/weatherAUS.csv'"]}]},{"cell_type":"code","source":["df.shapef.head()"],"metadata":{"id":"pwWTOs1rmMUh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["col_names = df.columns\n","col_names"],"metadata":{"id":"Kvu_QfVhnFi_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.drop(['RISK_MM'],axis=1,inplace=TRUE)"],"metadata":{"id":"x9Z_5Q-4nK3Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.info()"],"metadata":{"id":"ty48uoIenXiy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# find categorical variables\n","\n","categorical = [var for var in df.columns if df[var].dtype=='O']\n","\n","print('There are {} categorical variables\\n'.format(len(categorical)))\n","\n","print('The categorical variables are :', categorical)"],"metadata":{"id":"dPzOi6KCnwHo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# view the categorical variables\n","\n","df[categorical].head()"],"metadata":{"id":"8ReX5nc_nzCt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# check missing values in categorical variables\n","\n","df[categorical].isnull().sum()"],"metadata":{"id":"67HGtlSMn1ex"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# print categorical variables containing missing values\n","\n","cat1 = [var for var in categorical if df[var].isnull().sum()!=0]\n","\n","print(df[cat1].isnull().sum())"],"metadata":{"id":"EdBA0YBKn_bi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# view frequency of categorical variables\n","\n","for var in categorical:\n","\n","    print(df[var].value_counts())"],"metadata":{"id":"dr2X9sNloMmN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# view frequency distribution of categorical variables\n","\n","for var in categorical:\n","\n","    print(df[var].value_counts()/np.float(len(df)))"],"metadata":{"id":"CrpjDIKUoOwc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# check for cardinality in categorical variables\n","\n","for var in categorical:\n","\n","    print(var, ' contains ', len(df[var].unique()), ' labels')"],"metadata":{"id":"-bKKRJywoSkN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['Date'].dtypes"],"metadata":{"id":"quH4WxOhofQ-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# parse the dates, currently coded as strings, into datetime format\n","\n","df['Date'] = pd.to_datetime(df['Date'])"],"metadata":{"id":"i_5K3FRWpDsA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# extract year from date\n","\n","df['Year'] = df['Date'].dt.year\n","\n","df['Year'].head()"],"metadata":{"id":"0EHsoIPRpEZz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# extract month from date\n","\n","df['Month'] = df['Date'].dt.month\n","\n","df['Month'].head()"],"metadata":{"id":"dT8hqE7SpImW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# extract day from date\n","\n","df['Day'] = df['Date'].dt.day\n","\n","df['Day'].head()"],"metadata":{"id":"HBR0QQDDpLcc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# again view the summary of dataset\n","\n","df.info()"],"metadata":{"id":"OA4uzBWkpNuL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# drop the original Date variable\n","\n","df.drop('Date', axis=1, inplace = True)"],"metadata":{"id":"1u5NIAFlpchu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# preview the dataset again\n","\n","df.head()"],"metadata":{"id":"AXgNjrvtpfFk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# find categorical variables\n","\n","categorical = [var for var in df.columns if df[var].dtype=='O']\n","\n","print('There are {} categorical variables\\n'.format(len(categorical)))\n","\n","print('The categorical variables are :', categorical)"],"metadata":{"id":"A75D0LP8pg7X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# check for missing values in categorical variables\n","\n","df[categorical].isnull().sum()"],"metadata":{"id":"AXuVmq6SpmVO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# print number of labels in Location variable\n","\n","print('Location contains', len(df.Location.unique()), 'labels')"],"metadata":{"id":"QjbFgwYDpouR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# check labels in location variable\n","\n","df.Location.unique()"],"metadata":{"id":"_K2CU3DMprLA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# let's do One Hot Encoding of Location variable\n","# get k-1 dummy variables after One Hot Encoding\n","# preview the dataset with head() method\n","\n","pd.get_dummies(df.Location, drop_first=True).head()"],"metadata":{"id":"9j58WRiYpteZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# print number of labels in WindGustDir variable\n","\n","print('WindGustDir contains', len(df['WindGustDir'].unique()), 'labels')"],"metadata":{"id":"Q7eVp90Bp_l9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# check labels in WindGustDir variable\n","\n","df['WindGustDir'].unique()"],"metadata":{"id":"lI83o1BVqp3b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# check frequency distribution of values in WindGustDir variable\n","\n","df.WindGustDir.value_counts()"],"metadata":{"id":"bHpa3Lh4q0l0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# let's do One Hot Encoding of WindGustDir variable\n","# get k-1 dummy variables after One Hot Encoding\n","# also add an additional dummy variable to indicate there was missing data\n","# preview the dataset with head() method\n","\n","pd.get_dummies(df.WindGustDir, drop_first=True, dummy_na=True).head()"],"metadata":{"id":"qatZ7_uPq3EV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# sum the number of 1s per boolean variable over the rows of the dataset\n","# it will tell us how many observations we have for each category\n","\n","pd.get_dummies(df.WindGustDir, drop_first=True, dummy_na=True).sum(axis=0)"],"metadata":{"id":"OniuTN2qrJqe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# print number of labels in WindDir9am variable\n","\n","print('WindDir9am contains', len(df['WindDir9am'].unique()), 'labels')"],"metadata":{"id":"7LKF6Bx0sWfw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# check labels in WindDir9am variable\n","\n","df['WindDir9am'].unique()"],"metadata":{"id":"yH3Wg3Oxstog"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# check frequency distribution of values in WindDir9am variable\n","\n","df['WindDir9am'].value_counts()"],"metadata":{"id":"nDdIyVa3sx3d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# let's do One Hot Encoding of WindDir9am variable\n","# get k-1 dummy variables after One Hot Encoding\n","# also add an additional dummy variable to indicate there was missing data\n","# preview the dataset with head() method\n","\n","pd.get_dummies(df.WindDir9am, drop_first=True, dummy_na=True).head()"],"metadata":{"id":"nZRf3jpts0k9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# let's do One Hot Encoding of WindDir9am variable\n","# get k-1 dummy variables after One Hot Encoding\n","# also add an additional dummy variable to indicate there was missing data\n","# preview the dataset with head() method\n","\n","pd.get_dummies(df.WindDir9am, drop_first=True, dummy_na=True).head()"],"metadata":{"id":"F0MU4RQVtNop"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# sum the number of 1s per boolean variable over the rows of the dataset\n","# it will tell us how many observations we have for each category\n","\n","pd.get_dummies(df.WindDir9am, drop_first=True, dummy_na=True).sum(axis=0)"],"metadata":{"id":"1wMjon-xtZuF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# print number of labels in WindDir3pm variable\n","\n","print('WindDir3pm contains', len(df['WindDir3pm'].unique()), 'labels')"],"metadata":{"id":"FMFa5zjjtcnq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# check labels in WindDir3pm variable\n","\n","df['WindDir3pm'].unique()"],"metadata":{"id":"DWzptAADtgT2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# check frequency distribution of values in WindDir3pm variable\n","\n","df['WindDir3pm'].value_counts()"],"metadata":{"id":"7UMeL0KvtrBC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# let's do One Hot Encoding of WindDir3pm variable\n","# get k-1 dummy variables after One Hot Encoding\n","# also add an additional dummy variable to indicate there was missing data\n","# preview the dataset with head() method\n","\n","pd.get_dummies(df.WindDir3pm, drop_first=True, dummy_na=True).head()"],"metadata":{"id":"Z3kaggXptshQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# sum the number of 1s per boolean variable over the rows of the dataset\n","# it will tell us how many observations we have for each category\n","\n","pd.get_dummies(df.WindDir3pm, drop_first=True, dummy_na=True).sum(axis=0)"],"metadata":{"id":"SXv2e9nLtzoM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# print number of labels in RainToday variable\n","\n","print('RainToday contains', len(df['RainToday'].unique()), 'labels')"],"metadata":{"id":"FkV-ith6Vq4r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# check labels in WindGustDir variable\n","\n","df['RainToday'].unique()"],"metadata":{"id":"htU4aJeGVvBs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# check frequency distribution of values in WindGustDir variable\n","\n","df.RainToday.value_counts()"],"metadata":{"id":"CMfrv8VNVw1i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# let's do One Hot Encoding of RainToday variable\n","# get k-1 dummy variables after One Hot Encoding\n","# also add an additional dummy variable to indicate there was missing data\n","# preview the dataset with head() method\n","\n","pd.get_dummies(df.RainToday, drop_first=True, dummy_na=True).head()"],"metadata":{"id":"HQRBc0ZKVy4M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# sum the number of 1s per boolean variable over the rows of the dataset\n","# it will tell us how many observations we have for each category\n","\n","pd.get_dummies(df.RainToday, drop_first=True, dummy_na=True).sum(axis=0)"],"metadata":{"id":"B3YJ8qi6V2Dc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# find numerical variables\n","\n","numerical = [var for var in df.columns if df[var].dtype!='O']\n","\n","print('There are {} numerical variables\\n'.format(len(numerical)))\n","\n","print('The numerical variables are :', numerical)"],"metadata":{"id":"TkjcAMxZV-AU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# view the numerical variables\n","\n","df[numerical].head()"],"metadata":{"id":"IftvYu9pWAkc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# check missing values in numerical variables\n","\n","df[numerical].isnull().sum()"],"metadata":{"id":"xkPXICZnWFgc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# view summary statistics in numerical variables\n","\n","print(round(df[numerical].describe()),2)"],"metadata":{"id":"SuokjKTMWJUy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# draw boxplots to visualize outliers\n","\n","plt.figure(figsize=(15,10))\n","\n","\n","plt.subplot(2, 2, 1)\n","fig = df.boxplot(column='Rainfall')\n","fig.set_title('')\n","fig.set_ylabel('Rainfall')\n","\n","\n","plt.subplot(2, 2, 2)\n","fig = df.boxplot(column='Evaporation')\n","fig.set_title('')\n","fig.set_ylabel('Evaporation')\n","\n","\n","plt.subplot(2, 2, 3)\n","fig = df.boxplot(column='WindSpeed9am')\n","fig.set_title('')\n","fig.set_ylabel('WindSpeed9am')\n","\n","\n","plt.subplot(2, 2, 4)\n","fig = df.boxplot(column='WindSpeed3pm')\n","fig.set_title('')\n","fig.set_ylabel('WindSpeed3pm')"],"metadata":{"id":"elpS-8e-WMah"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# plot histogram to check distribution\n","\n","plt.figure(figsize=(15,10))\n","\n","\n","plt.subplot(2, 2, 1)\n","fig = df.Rainfall.hist(bins=10)\n","fig.set_xlabel('Rainfall')\n","fig.set_ylabel('RainTomorrow')\n","\n","\n","plt.subplot(2, 2, 2)\n","fig = df.Evaporation.hist(bins=10)\n","fig.set_xlabel('Evaporation')\n","fig.set_ylabel('RainTomorrow')\n","\n","\n","plt.subplot(2, 2, 3)\n","fig = df.WindSpeed9am.hist(bins=10)\n","fig.set_xlabel('WindSpeed9am')\n","fig.set_ylabel('RainTomorrow')\n","\n","\n","plt.subplot(2, 2, 4)\n","fig = df.WindSpeed3pm.hist(bins=10)\n","fig.set_xlabel('WindSpeed3pm')\n","fig.set_ylabel('RainTomorrow')"],"metadata":{"id":"irCziSCQWeuO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# find outliers for Rainfall variable\n","\n","IQR = df.Rainfall.quantile(0.75) - df.Rainfall.quantile(0.25)\n","Lower_fence = df.Rainfall.quantile(0.25) - (IQR * 3)\n","Upper_fence = df.Rainfall.quantile(0.75) + (IQR * 3)\n","print('Rainfall outliers are values < {lowerboundary} or > {upperboundary}'.format(lowerboundary=Lower_fence, upperboundary=Upper_fence))"],"metadata":{"id":"TmZCde0HW_qb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# find outliers for Evaporation variable\n","\n","IQR = df.Evaporation.quantile(0.75) - df.Evaporation.quantile(0.25)\n","Lower_fence = df.Evaporation.quantile(0.25) - (IQR * 3)\n","Upper_fence = df.Evaporation.quantile(0.75) + (IQR * 3)\n","print('Evaporation outliers are values < {lowerboundary} or > {upperboundary}'.format(lowerboundary=Lower_fence, upperboundary=Upper_fence))"],"metadata":{"id":"0XBeefKPXP9s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# find outliers for WindSpeed9am variable\n","\n","IQR = df.WindSpeed9am.quantile(0.75) - df.WindSpeed9am.quantile(0.25)\n","Lower_fence = df.WindSpeed9am.quantile(0.25) - (IQR * 3)\n","Upper_fence = df.WindSpeed9am.quantile(0.75) + (IQR * 3)\n","print('WindSpeed9am outliers are values < {lowerboundary} or > {upperboundary}'.format(lowerboundary=Lower_fence, upperboundary=Upper_fence))"],"metadata":{"id":"daR1g5PGXonI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# find outliers for WindSpeed3pm variable\n","\n","IQR = df.WindSpeed3pm.quantile(0.75) - df.WindSpeed3pm.quantile(0.25)\n","Lower_fence = df.WindSpeed3pm.quantile(0.25) - (IQR * 3)\n","Upper_fence = df.WindSpeed3pm.quantile(0.75) + (IQR * 3)\n","print('WindSpeed3pm outliers are values < {lowerboundary} or > {upperboundary}'.format(lowerboundary=Lower_fence, upperboundary=Upper_fence))"],"metadata":{"id":"00XTS6arYT7-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X = df.drop(['RainTomorrow'], axis=1)\n","\n","y = df['RainTomorrow']"],"metadata":{"id":"3R_wLZsgYa8U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# split X and y into training and testing sets\n","\n","from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"],"metadata":{"id":"1KP1G_iiYbfZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# check the shape of X_train and X_test\n","\n","X_train.shape, X_test.shape"],"metadata":{"id":"edgle6_hYbp-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# check data types in X_train\n","\n","X_train.dtypes"],"metadata":{"id":"IvW3UhnuYb2j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# display categorical variables\n","\n","categorical = [col for col in X_train.columns if X_train[col].dtypes == 'O']\n","\n","categorical"],"metadata":{"id":"bybRi6gkZCtF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#display numerical Variables\n","numerical = [col for col in X_train.columns if X_train[col].dtypes != 'O']\n","\n","numerical"],"metadata":{"id":"Jt9IT7DIZjJA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# check missing values in numerical variables in X_train\n","\n","X_train[numerical].isnull().sum()"],"metadata":{"id":"CdP8PZP8Z88A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# check missing values in numerical variables in X_test\n","\n","X_test[numerical].isnull().sum()"],"metadata":{"id":"POEz2SqbZ_T6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# print percentage of missing values in the numerical variables in training set\n","\n","for col in numerical:\n","    if X_train[col].isnull().mean()>0:\n","        print(col, round(X_train[col].isnull().mean(),4))"],"metadata":{"id":"zUxxIp51aYcu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# impute missing values in X_train and X_test with respective column median in X_train\n","\n","for df1 in [X_train,X_test]:\n","    for col in numerical:\n","        col_median=X_train[col].median()\n","        df1[col] = df1[col].fillna(col_median,inplace =True)"],"metadata":{"id":"0vSIZOjLamzk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# check again missing values in numerical variables in X_train\n","\n","X_train[numerical].isnull().sum()"],"metadata":{"id":"hM4KwGxWbLTF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# check missing values in numerical variables in X_test\n","\n","X_test[numerical].isnull().sum()"],"metadata":{"id":"tTd6Gh1mbPwG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# print percentage of missing values in the categorical variables in training set\n","\n","X_train[categorical].isnull().mean()"],"metadata":{"id":"8eePelBrb42W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# print categorical variables with missing data\n","\n","for col in categorical:\n","    if X_train[col].isnull().mean()>0:\n","        print(col, (X_train[col].isnull().mean()))"],"metadata":{"id":"gO4FRhxQcM8u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# impute missing categorical variables with most frequent value\n","\n","for df2 in [X_train, X_test]:\n","    df2['WindGustDir'].fillna(X_train['WindGustDir'].mode()[0], inplace=True)\n","    df2['WindDir9am'].fillna(X_train['WindDir9am'].mode()[0], inplace=True)\n","    df2['WindDir3pm'].fillna(X_train['WindDir3pm'].mode()[0], inplace=True)\n","    df2['RainToday'].fillna(X_train['RainToday'].mode()[0], inplace=True)"],"metadata":{"id":"T6i6H15acuWU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# check missing values in categorical variables in X_train\n","\n","X_train[categorical].isnull().sum()"],"metadata":{"id":"Hqpxxv_lcui7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# check missing values in categorical variables in X_test\n","\n","X_test[categorical].isnull().sum()"],"metadata":{"id":"Us-E50Bzcun4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# check missing values in X_train\n","\n","X_train.isnull().sum()"],"metadata":{"id":"fqq0V2vecusk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# check missing values in X_test\n","\n","X_test.isnull().sum()"],"metadata":{"id":"KMXtEZRJeItc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def max_value(df3, variable, top):\n","    return np.where(df3[variable]>top, top, df3[variable])\n","\n","for df3 in [X_train, X_test]:\n","    df3['Rainfall'] = max_value(df3, 'Rainfall', 3.2)\n","    df3['Evaporation'] = max_value(df3, 'Evaporation', 21.8)\n","    df3['WindSpeed9am'] = max_value(df3, 'WindSpeed9am', 55)\n","    df3['WindSpeed3pm'] = max_value(df3, 'WindSpeed3pm', 57)"],"metadata":{"id":"D6fDczo2eIxf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train.Rainfall.max(), X_test.Rainfall.max()"],"metadata":{"id":"VFNTrhrueI0a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train.Evaporation.max(), X_test.Evaporation.max()"],"metadata":{"id":"oQy1Ou6leI4P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train.WindSpeed9am.max(), X_test.WindSpeed9am.max()"],"metadata":{"id":"xz6eelileI7j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train.WindSpeed3pm.max(), X_test.WindSpeed3pm.max()"],"metadata":{"id":"ixNbeN-mcuv2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train[numerical].describe()"],"metadata":{"id":"ZiG_HF2gcuyj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["categorical"],"metadata":{"id":"DoL1aAdPfBFE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train[categorical].head()"],"metadata":{"id":"4-tQ_anRfBKn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# encode RainToday variable\n","\n","import category_encoders as ce\n","\n","encoder = ce.BinaryEncoder(cols=['RainToday'])\n","\n","X_train = encoder.fit_transform(X_train)\n","\n","X_test = encoder.transform(X_test)"],"metadata":{"id":"BRR-ibURfGnV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train.head()"],"metadata":{"id":"hP5LnYCGfGsx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train = pd.concat([X_train[numerical], X_train[['RainToday_0', 'RainToday_1']],\n","                     pd.get_dummies(X_train.Location),\n","                     pd.get_dummies(X_train.WindGustDir),\n","                     pd.get_dummies(X_train.WindDir9am),\n","                     pd.get_dummies(X_train.WindDir3pm)], axis=1)"],"metadata":{"id":"_kFjVOl6fGyg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train.head()"],"metadata":{"id":"DohIqH1DfBQS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_test = pd.concat([X_test[numerical], X_test[['RainToday_0', 'RainToday_1']],\n","                     pd.get_dummies(X_test.Location),\n","                     pd.get_dummies(X_test.WindGustDir),\n","                     pd.get_dummies(X_test.WindDir9am),\n","                     pd.get_dummies(X_test.WindDir3pm)], axis=1)"],"metadata":{"id":"BlK0_pKcfBVp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_test.head()"],"metadata":{"id":"eX3k05MufgQg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train.describe()"],"metadata":{"id":"Pq32NEpRfgVC","executionInfo":{"status":"ok","timestamp":1718364808528,"user_tz":-330,"elapsed":482,"user":{"displayName":"The Ghost Man","userId":"00574377802751596480"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cols = X_train.columns"],"metadata":{"id":"jt_iPpYsfgZp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import MinMaxScaler\n","\n","scaler = MinMaxScaler()\n","\n","X_train = scaler.fit_transform(X_train)\n","\n","X_test = scaler.transform(X_test)"],"metadata":{"id":"wSW7cub7fgds"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train = pd.DataFrame(X_train, columns=[cols])"],"metadata":{"id":"ZTUf6YJQfBZq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_test = pd.DataFrame(X_test, columns=[cols])"],"metadata":{"id":"arTcqtQ-hyIR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train.describe()"],"metadata":{"id":"qzzh8GHThyLO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# train a logistic regression model on the training set\n","from sklearn.linear_model import LogisticRegression\n","\n","\n","# instantiate the model\n","logreg = LogisticRegression(solver='liblinear', random_state=0)\n","\n","\n","# fit the model\n","logreg.fit(X_train, y_train)"],"metadata":{"id":"4SSQpj7ihyOI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred_test = logreg.predict(X_test)\n","\n","y_pred_test"],"metadata":{"id":"uk3schNNhyQo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# probability of getting output as 0 - no rain\n","\n","logreg.predict_proba(X_test)[:,0]"],"metadata":{"id":"cf29LC8ahyTc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# probability of getting output as 1 - rain\n","\n","logreg.predict_proba(X_test)[:,1]"],"metadata":{"id":"uUZqZZ2BhyWV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score\n","\n","print('Model accuracy score: {0:0.4f}'. format(accuracy_score(y_test, y_pred_test)))"],"metadata":{"id":"0MTosa_2hycN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred_train = logreg.predict(X_train)\n","\n","y_pred_train"],"metadata":{"id":"ZIoR2WXXhyd3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Training-set accuracy score: {0:0.4f}'. format(accuracy_score(y_train, y_pred_train)))"],"metadata":{"id":"NGhS6I9Bhyfr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# print the scores on training and test set\n","\n","print('Training set score: {:.4f}'.format(logreg.score(X_train, y_train)))\n","\n","print('Test set score: {:.4f}'.format(logreg.score(X_test, y_test)))"],"metadata":{"id":"WwVcCTpXq7Fc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# fit the Logsitic Regression model with C=100\n","\n","# instantiate the model\n","logreg100 = LogisticRegression(C=100, solver='liblinear', random_state=0)\n","\n","\n","# fit the model\n","logreg100.fit(X_train, y_train)"],"metadata":{"id":"hPKtYaTMq7MO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# print the scores on training and test set\n","\n","print('Training set score: {:.4f}'.format(logreg100.score(X_train, y_train)))\n","\n","print('Test set score: {:.4f}'.format(logreg100.score(X_test, y_test)))"],"metadata":{"id":"KSPMhe-yq7St"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# fit the Logsitic Regression model with C=001\n","\n","# instantiate the model\n","logreg001 = LogisticRegression(C=0.01, solver='liblinear', random_state=0)\n","\n","\n","# fit the model\n","logreg001.fit(X_train, y_train)"],"metadata":{"id":"rqkcLHsgq7aI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# print the scores on training and test set\n","\n","print('Training set score: {:.4f}'.format(logreg001.score(X_train, y_train)))\n","\n","print('Test set score: {:.4f}'.format(logreg001.score(X_test, y_test)))"],"metadata":{"id":"xxZHYzoVIui2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# check class distribution in test set\n","\n","y_test.value_counts()"],"metadata":{"id":"N1FZW2HVIupR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# check null accuracy score\n","\n","null_accuracy = (22067/(22067+6372))\n","\n","print('Null accuracy score: {0:0.4f}'. format(null_accuracy))"],"metadata":{"id":"2whiJPlEIuvm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Print the Confusion Matrix and slice it into four pieces\n","\n","from sklearn.metrics import confusion_matrix\n","\n","cm = confusion_matrix(y_test, y_pred_test)\n","\n","print('Confusion matrix\\n\\n', cm)\n","\n","print('\\nTrue Positives(TP) = ', cm[0,0])\n","\n","print('\\nTrue Negatives(TN) = ', cm[1,1])\n","\n","print('\\nFalse Positives(FP) = ', cm[0,1])\n","\n","print('\\nFalse Negatives(FN) = ', cm[1,0])"],"metadata":{"id":"axNbXsjjIu1k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# visualize confusion matrix with seaborn heatmap\n","\n","cm_matrix = pd.DataFrame(data=cm, columns=['Actual Positive:1', 'Actual Negative:0'],\n","                                 index=['Predict Positive:1', 'Predict Negative:0'])\n","\n","sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')"],"metadata":{"id":"IZWhkPdqKDYe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import classification_report\n","\n","print(classification_report(y_test, y_pred_test))"],"metadata":{"id":"GmVGxD9iKDd2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["TP = cm[0,0]\n","TN = cm[1,1]\n","FP = cm[0,1]\n","FN = cm[1,0]"],"metadata":{"id":"eKL0vbkpKDiD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# print classification accuracy\n","\n","classification_accuracy = (TP + TN) / float(TP + TN + FP + FN)\n","\n","print('Classification accuracy : {0:0.4f}'.format(classification_accuracy))"],"metadata":{"id":"XhEblQgtKDmJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# print classification error\n","\n","classification_error = (FP + FN) / float(TP + TN + FP + FN)\n","\n","print('Classification error : {0:0.4f}'.format(classification_error))"],"metadata":{"id":"M1-R6vX5KDs2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# print precision score\n","\n","precision = TP / float(TP + FP)\n","\n","\n","print('Precision : {0:0.4f}'.format(precision))"],"metadata":{"id":"56ZGlaRNKtaC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["recall = TP / float(TP + FN)\n","\n","print('Recall or Sensitivity : {0:0.4f}'.format(recall))"],"metadata":{"id":"xsYP4HK8KtgZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["true_positive_rate = TP / float(TP + FN)\n","\n","\n","print('True Positive Rate : {0:0.4f}'.format(true_positive_rate))"],"metadata":{"id":"NJS30z4eKtlE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["false_positive_rate = FP / float(FP + TN)\n","\n","\n","print('False Positive Rate : {0:0.4f}'.format(false_positive_rate))"],"metadata":{"id":"gvAwdqQ0Ktqz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["specificity = TN / (TN + FP)\n","\n","print('Specificity : {0:0.4f}'.format(specificity))"],"metadata":{"id":"0R8XRQMFKtxz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# print the first 10 predicted probabilities of two classes- 0 and 1\n","\n","y_pred_prob = logreg.predict_proba(X_test)[0:10]\n","\n","y_pred_prob"],"metadata":{"id":"XjEA694ZIu7A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# store the probabilities in dataframe\n","\n","y_pred_prob_df = pd.DataFrame(data=y_pred_prob, columns=['Prob of - No rain tomorrow (0)', 'Prob of - Rain tomorrow (1)'])\n","\n","y_pred_prob_df"],"metadata":{"id":"YiHow9L2La-9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# print the first 10 predicted probabilities for class 1 - Probability of rain\n","\n","logreg.predict_proba(X_test)[0:10, 1]"],"metadata":{"id":"xYkw9xiXN4pU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# store the predicted probabilities for class 1 - Probability of rain\n","\n","y_pred1 = logreg.predict_proba(X_test)[:, 1]"],"metadata":{"id":"sk4vEZjwN4xk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# plot histogram of predicted probabilities\n","\n","\n","# adjust the font size\n","plt.rcParams['font.size'] = 12\n","\n","\n","# plot histogram with 10 bins\n","plt.hist(y_pred1, bins = 10)\n","\n","\n","# set the title of predicted probabilities\n","plt.title('Histogram of predicted probabilities of rain')\n","\n","\n","# set the x-axis limit\n","plt.xlim(0,1)\n","\n","\n","# set the title\n","plt.xlabel('Predicted probabilities of rain')\n","plt.ylabel('Frequency')"],"metadata":{"id":"Ct44uJbLN5KH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import binarize\n","\n","for i in range(1,5):\n","\n","    cm1=0\n","\n","    y_pred1 = logreg.predict_proba(X_test)[:,1]\n","\n","    y_pred1 = y_pred1.reshape(-1,1)\n","\n","    y_pred2 = binarize(y_pred1, i/10)\n","\n","    y_pred2 = np.where(y_pred2 == 1, 'Yes', 'No')\n","\n","    cm1 = confusion_matrix(y_test, y_pred2)\n","\n","    print ('With',i/10,'threshold the Confusion Matrix is ','\\n\\n',cm1,'\\n\\n',\n","\n","            'with',cm1[0,0]+cm1[1,1],'correct predictions, ', '\\n\\n',\n","\n","            cm1[0,1],'Type I errors( False Positives), ','\\n\\n',\n","\n","            cm1[1,0],'Type II errors( False Negatives), ','\\n\\n',\n","\n","           'Accuracy score: ', (accuracy_score(y_test, y_pred2)), '\\n\\n',\n","\n","           'Sensitivity: ',cm1[1,1]/(float(cm1[1,1]+cm1[1,0])), '\\n\\n',\n","\n","           'Specificity: ',cm1[0,0]/(float(cm1[0,0]+cm1[0,1])),'\\n\\n',\n","\n","            '====================================================', '\\n\\n')"],"metadata":{"id":"f6Tfz_LYSFd-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# plot ROC Curve\n","\n","from sklearn.metrics import roc_curve\n","\n","fpr, tpr, thresholds = roc_curve(y_test, y_pred1, pos_label = 'Yes')\n","\n","plt.figure(figsize=(6,4))\n","\n","plt.plot(fpr, tpr, linewidth=2)\n","\n","plt.plot([0,1], [0,1], 'k--' )\n","\n","plt.rcParams['font.size'] = 12\n","\n","plt.title('ROC curve for RainTomorrow classifier')\n","\n","plt.xlabel('False Positive Rate (1 - Specificity)')\n","\n","plt.ylabel('True Positive Rate (Sensitivity)')\n","\n","plt.show()"],"metadata":{"id":"QITejDBHSFuT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# compute ROC AUC\n","\n","from sklearn.metrics import roc_auc_score\n","\n","ROC_AUC = roc_auc_score(y_test, y_pred1)\n","\n","print('ROC AUC : {:.4f}'.format(ROC_AUC))"],"metadata":{"id":"NPN1QcisSF4O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# calculate cross-validated ROC AUC\n","\n","from sklearn.model_selection import cross_val_score\n","\n","Cross_validated_ROC_AUC = cross_val_score(logreg, X_train, y_train, cv=5, scoring='roc_auc').mean()\n","\n","print('Cross validated ROC AUC : {:.4f}'.format(Cross_validated_ROC_AUC))"],"metadata":{"id":"quaj39rfSGER"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Applying 5-Fold Cross Validation\n","\n","from sklearn.model_selection import cross_val_score\n","\n","scores = cross_val_score(logreg, X_train, y_train, cv = 5, scoring='accuracy')\n","\n","print('Cross-validation scores:{}'.format(scores))"],"metadata":{"id":"tBcNn7ibSGOv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# compute Average cross-validation score\n","\n","print('Average cross-validation score: {:.4f}'.format(scores.mean()))"],"metadata":{"id":"71XceNfNeJjP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import GridSearchCV\n","\n","\n","parameters = [{'penalty':['l1','l2']},\n","              {'C':[1, 10, 100, 1000]}]\n","\n","\n","\n","grid_search = GridSearchCV(estimator = logreg,\n","                           param_grid = parameters,\n","                           scoring = 'accuracy',\n","                           cv = 5,\n","                           verbose=0)\n","\n","\n","grid_search.fit(X_train, y_train)"],"metadata":{"id":"VCGLKKi8eJrY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# examine the best model\n","\n","# best score achieved during the GridSearchCV\n","print('GridSearch CV best score : {:.4f}\\n\\n'.format(grid_search.best_score_))\n","\n","# print parameters that give the best results\n","print('Parameters that give the best results :','\\n\\n', (grid_search.best_params_))\n","\n","# print estimator that was chosen by the GridSearch\n","print('\\n\\nEstimator that was chosen by the search :','\\n\\n', (grid_search.best_estimator_))"],"metadata":{"id":"2GNdcq_rfadm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# calculate GridSearch CV score on test set\n","\n","print('GridSearch CV score on test set: {0:0.4f}'.format(grid_search.score(X_test, y_test)))"],"metadata":{"id":"9eH61vwZfakH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"tsmQ_bYafaoM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"WQgv5Lj4eJy-"},"execution_count":null,"outputs":[]}]}